<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">

<head>
<!--#config timefmt="%A, %d %B %Y - %R" -->
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />

<!-- CORRECT HERE: This is REALLY needed all search engines and bookmark manager love this; please use this format: -->
<title>Petr Kellnhofer</title>

<!--<link rel="shortcut icon" href="https://cfg.mit.edu/sites/cfg.mit.edu/themes/cfgv2_bootstrap_theme/favicon.ico" type="image/vnd.microsoft.icon">-->
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<link rel="stylesheet" type="text/css" media="screen" href="stylesheet.css?v=5" />

</head>
<body>
	<!-- Main menu -->
	<nav class="bg-blue nav-top">
		<div class="container no-spacing">
			

			<div class="right">
				<div class="nav-main">
				
					<ul>
						<li class="nav-main__mainitem" data-priority="0"><a href="#">Home</a></li>
						<li class="nav-main__mainitem" data-priority="0"><a href="#teaching">Teaching</a>
							
						</li>
						<li class="nav-main__mainitem" data-priority="0"><a href="#supervision">Supervision</a></li>
						<li class="nav-main__mainitem" data-priority="0"><a href="#publications">Publications</a></li>
					</ul>
				</div>
			</div>
		</div>
	</nav>

	<!-- Content -->
  <div id="content" class="">
	<div class="slide-block">
		<!-- CORRECT HERE: Optional - your photo here; Required - lastname, first name, phone, room etc. - use a smaller size if needed -->
		<img src="photo_ski.jpg" alt="Petr Kellnhofer" height="240" style="border: 2px solid rgb(171, 194, 214); margin-left: 5px; margin-top: 5px; margin-bottom: 5px;"/>
	</div>
	<div class="slide-block">
		<h1>Petr Kellnhofer</h1>
		
		<p>
			<strong>Address:</strong> Van Mourik Broekmanweg 6, Room W.5.900 Building 28, 2628 XE Delft, The Netherlands<br />
			<strong>Email:</strong> p.kell<span/>nhofer [a.t) tudelft_do#t_nl<br />
			<br />
			<a href="https://scholar.google.com/citations?user=Lh54BvgAAAAJ&hl=en">Google Scholar</a><br />
		</p>
    </div>
	<div class="clr"></div>
	  
    <p>
	I am an Assistant Professor in the <a href="https://graphics.tudelft.nl/">Computer Graphics and Visualization Group</a> at <a href="https://www.tudelft.nl/en/">Delft University of Technology</a>. I conduct research in computational imaging and displays covering both perceptual aspects of AR/VR/lightfield displays as well as computer vision techniques for 3D scene representation including neural rendering.
</p>
<p>
	Previously, I was a Visiting Scholar in the <a href="http://computationalimaging.org/">Stanford Computational Imaging Lab</a> of <a href="https://stanford.edu/~gordonwz/">Prof. Gordon Wetzstein</a> at <a href="https://www.stanford.edu/">Stanford University</a> and Senior Technical Staff member at <a href="http://www.raxium.com/">Raxium</a> between 2019 and 2021.
	Between 2017 and 2019, I was a Postdoctoral Associate in the <a href="http://cfg.mit.edu/">Computational Fabrication Group</a> of <a href="http://people.csail.mit.edu/wojciech/">Prof. Wojciech Matusik</a> at <a href="https://www.csail.mit.edu/">MIT CSAIL</a>.
	Between 2012 and 2016, I was a PhD Student in the <a href="http://www.mpi-inf.mpg.de/departments/computer-graphics/">Computer Graphics Department</a> at MPI Informatik and Saarland University where I work on <a href="https://publikationen.sulb.uni-saarland.de/handle/20.500.11880/26730">Perceptual modeling for stereoscopic 3D</a> under supervision of <a href="http://people.mpi-inf.mpg.de/~karol/">Prof. Karol Myszkowski</a> and <a href="http://people.mpi-inf.mpg.de/~hpseidel/">Prof. Hans-Peter Seidel</a>.<br />
</p>
	
	

	<h3 id="research-interests" class="clearpara">Research Interests</h3>
    <ul>
	  <li>Neural rendering and generative AI (<a href="https://www.matthewtancik.com/nerf">NeRF</a>, <a href="https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/">3D Gaussians</a>, <a href="https://research.nvidia.com/labs/toronto-ai/DMTet/">differentiable rendering</a>,...) with focus on interaction (<a href="https://lukas.uzolas.com/Articulated-Point-NeRF/">reposing</a>, <a href="https://lukas.uzolas.com/MotionDreamer/">animation</a>, <a href="https://resolver.tudelft.nl/uuid:2e4df797-34ee-4c7c-aad7-694303ce5745">physics</a>, <a href="https://spinnerf3d.github.io/">editing</a>,...)</li>
	  <li>Computational imaging and deep learning (<a href="https://www.computationalimaging.org/publications/gnarf/">GANs</a>, <a href="https://www.computationalimaging.org/publications/state-of-the-art-on-diffusion-models-for-visual-computing/">Diffusion</a>,...)</li>
	  <li>Computational displays and perceptual rendering (<a href="https://www.computationalimaging.org/publications/attention-aware/">Foveation</a>, <a href="http://www.computationalimaging.org/publications/gcstereo/">VR</a>, <a href="https://cgh.csail.mit.edu/">holography</a>, <a href="https://resources.mpi-inf.mpg.de/StereoParallax/">stereoscopy</a>, <a href="http://www.computationalimaging.org/publications/cff/">high refresh-rate</a>, <a href="https://resources.mpi-inf.mpg.de/TransformationAwareMetric/#jei">image metrics</a>...)</li>
      <li>Neural sensing (extracting novels signals from <a href="https://github.com/CMU-Perceptual-Computing-Lab/openpose">RGB cameras</a>, <a href="https://stag.csail.mit.edu/">tactile arrays</a>, microphones,...)</li>
    </ul>
			
	
	  
    <h1 id="teaching" class="clearpara">Teaching</h1>
	
	<h3 id="open-positions" class="clearpara">MSc Thesis Topics</h3>
	<p>
		I am looking for enthusiastic TU Delft MSc students interested in projects related to my research interests to work on topics including but not limited to:
	</p>
    <ul>
	  <li>Investigating properties of neural <b>shape</b> representations (<a href="http://www.vovakim.com/papers/22_SIGGRAPH_NJF.pdf">Neural Jacobian Fields</a>, <a href="https://arxiv.org/pdf/2012.09164">NN for Pointclouds</a>, <a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Park_DeepSDF_Learning_Continuous_Signed_Distance_Functions_for_Shape_Representation_CVPR_2019_paper.pdf">Signed Distance Fields</a>, ...)</li>
	  <li>Implicit neural <b>appearance</b> representations for real-time 3D rendering (Focus on <a href="https://www.computationalimaging.org/publications/lsv/">visual fidelity and realism</a>)</li>
	  <li>Real-time 3D <b>interaction</b> from a <a href="https://www.tudelft.nl/en/eemcs/research/facilities/insyghtlab/">multi-view camera capture</a> (A combination of data capture, reconstruction, analysis and rendering)</li>
	  <li><b>Human visual attention</b> (A perceptual meaning of <a href="https://arxiv.org/abs/1701.01081">attending a visual feature</a>)</li>
	  <li><b>Perceptual relevance</b> of <a href="https://luciddreamer-cvlab.github.io/">computer vision metrics</a></li>
	  <li>...many others.</li>
    </ul>
	<p>Custom research ideas for MSc project are welcome and highly encouraged.</p>
	
	<h3>Courses</h3>
	<ul>
	  <li><a href="https://studiegids.tudelft.nl/courses/study-guide/educations/14757">DSAIT4120 Applied Image Processing (Q2)</a> (<a href="https://www.tudelft.nl/onderwijs/opleidingen/masters/cs/msc-computer-science/programme/themes/computer-graphics">MSc CS Theme "Computer Graphics"</a> & <a href="https://www.tudelft.nl/onderwijs/opleidingen/masters/dsait/msc-data-science-and-artificial-intelligence-technology/programme/themes/visual-computing">MSc DSAIT Theme "Visual Computing"</a>)</li>
	  <li><a href="https://studiegids.tudelft.nl/courses/study-guide/educations/14801">DSAIT4080 3D Visualization (Q3)</a> (<a href="https://www.tudelft.nl/onderwijs/opleidingen/masters/dsait/msc-data-science-and-artificial-intelligence-technology/programme/themes/interactive-visual-analysis">MSc DSAIT Theme "Interactive Visual Analysis"</a>)</li>
	  <li><a href="https://studiegids.tudelft.nl/courses/study-guide/educations/14817">DSAIT4130 3D Visual Computing (Q4)</a> (<a href="https://www.tudelft.nl/onderwijs/opleidingen/masters/dsait/msc-data-science-and-artificial-intelligence-technology/programme/themes/visual-computing">MSc DSAIT Theme "Visual Computing"</a>)</li>
	  <li><a href="https://studiegids.tudelft.nl/courses/study-guide/educations/14428">CS4705 Research Seminar Computer Graphics (Q4)</a> (<a href="https://www.tudelft.nl/onderwijs/opleidingen/masters/cs/msc-computer-science">MSc CS</a>)</li>	  
	  <li><a href="https://studiegids.tudelft.nl/courses/study-guide/educations/14485">DSAIT4215 Research in Visual Computing and Interactive Visual Analysis (Q4)</a> (<a href="https://www.tudelft.nl/onderwijs/opleidingen/masters/dsait/msc-data-science-and-artificial-intelligence-technology/programme">MSc DSAIT</a>)</li>
	  <li><a href="https://studiegids.tudelft.nl/courses/study-guide/educations/14369">TI3135TU Visual Data Processing (Q2)</a> (<a href="https://www.tudelft.nl/ewi/studeren/minoren/computer-science/">Minor CS</a>)</li>
    </ul>
	
	<h3>Lectures</h3>
	<ul>
		<li><a href="https://diglib.eg.org/handle/10.2312/egt20231030?show=full">Effective User Studies in Computer Graphics, Eurographics 2023, May 7th, 2023</a></li>
		<li><a href="https://github.com/erkil1452/gaze_workshop_public">Bridging the Technological Gap Workshop, Göttingen, Germany, July 31st – Aug 6th, 2022</a></li>
    </ul>
	
	<h1 id="supervision" class="clearpara">Supervision</h1>
	
	<h3>PhD students</h3>
	<ul>
	  <li><a href="https://www.tudelft.nl/ewi/over-de-faculteit/afdelingen/intelligent-systems/computer-graphics-and-visualization/people/lukas-uzolas">Lukas Uzolas</a></li>
	  <li><a href="https://www.tudelft.nl/ewi/over-de-faculteit/afdelingen/intelligent-systems/computer-graphics-and-visualization/people/guowei-lu">Guowei Lu</a></li>
    </ul>
	
	<h3>MSc projects</h3>
	<ul>
		<li><a href="https://resolver.tudelft.nl/uuid:2f42fdf6-d988-4096-957a-ab8d1d3bf5f2">Geometry-Guided Video Generation with Diffusion Feature Textures</a></li>
		<li><a href="http://resolver.tudelft.nl/uuid:cf7e4835-1cbe-4964-83be-c9201c513f08">Patch-Based Inpainting of 3D Gaussian Splatting</a></li>
		<li><a href="https://resolver.tudelft.nl/uuid:2e4df797-34ee-4c7c-aad7-694303ce5745">Gaussians as Supervision for Joint Physical Parameter Estimation and Appearance Reconstruction of Elastic Objects</a></li>		
    </ul>
		
	<h3>BSc projects</h3>
	<p>See the <a href="https://repository.tudelft.nl/person/Person_921956f5-0bd0-492a-af4e-8f8ab38f4b15?page=1">TU Delft Library Repository</a> for the student reports covering the past topics:</p>
	<ul>
	  <li>Pixel Art 2.0 (2024/25):
		<a href="https://resolver.tudelft.nl/uuid:259633b8-22b1-44d5-a91a-d6def7ad048a">#1</a>, 
		<a href="https://resolver.tudelft.nl/uuid:0aeec69b-b3fd-445d-96ed-e45bc2596e69">#2</a>, 
		<a href="https://resolver.tudelft.nl/uuid:b3c91b18-d9e8-48e0-91ce-8afafd2439d8">#3</a>, 
		<a href="https://resolver.tudelft.nl/uuid:c617a480-53fe-4e27-bfda-008cc718cee1">#4</a>
		<a href="https://resolver.tudelft.nl/uuid:59afd2a7-78f6-4859-8e5c-e6ddb508265d">#5</a>
	  </li>
	  <li>Procedural Tree Generation (2023/24):
		<a href="https://resolver.tudelft.nl/uuid:f39cf770-4bb9-4b2e-a3a4-88ad7f07a66a">#1</a>, 
		<a href="https://resolver.tudelft.nl/uuid:7ca6216f-2636-4c9c-85d3-f381b956870f">#2</a>, 
		<a href="https://resolver.tudelft.nl/uuid:433be09a-c741-421a-9b14-2929f2318d62">#3</a>, 
		<a href="https://resolver.tudelft.nl/uuid:13b5cb04-fdd8-4afe-90f2-0c02dfd5cbfc">#4</a>
	  </li>
	  <li>Neural Radiance Field (NeRF) as a Rendering Primitive (2022/23):
		<a href="https://resolver.tudelft.nl/uuid:8340b236-02c8-4709-ada5-1aa5038cc582">#1</a>, 
		<a href="https://resolver.tudelft.nl/uuid:f694a414-0c92-492f-a493-d604d88ce4e0">#2</a>, 
		<a href="https://resolver.tudelft.nl/uuid:d64b7da6-e681-4a5c-9d2a-fa68e02df4e2">#3</a>, 
		<a href="https://resolver.tudelft.nl/uuid:1d91b663-e35f-4bd5-a063-5c575ed9b14a">#4</a>
	  </li>
	  <li>Chromostereoscopy - From Color to Depth Perception (2021/22):
		<a href="https://resolver.tudelft.nl/uuid:178a950e-32c3-4397-a014-5a53d740ae74">#1</a>, 
		<a href="https://resolver.tudelft.nl/uuid:c571d44c-674b-440d-93c8-be1ef8390800">#2</a>, 
		<a href="https://resolver.tudelft.nl/uuid:75fd3cb7-da3e-4ce7-8e2c-708303a3127c">#3</a>, 
		<a href="https://resolver.tudelft.nl/uuid:d8d57050-2afc-4525-a9e2-05519b3f9577">#4</a>, 
		<a href="https://resolver.tudelft.nl/uuid:65a322e1-247c-4665-bb01-0c7e9e5db809">#5</a>		
	  </li>
    </ul>
    
	
	<h1 id="publications" class="clearpara">Publications</h1>

	
	<!-- CORRECT HERE: -->
	<!-- Examples on how to retrieve a list of your publications dynamically from the corresponding publication database. -->
	<!-- Put your name and the correct department in old style -->
	<!--<p><a href="http://domino.mpi-inf.mpg.de/intranet/ag1/ag1publ.nsf/ListPublications?OpenAgent&amp;author=Mehlhorn,+Kurt">Publications of Prof. Dr. Kurt Mehlhorn</a></p>-->
	<table>			
		<tbody>
		<tr class="year"><td colspan="2">2025</td></tr>	
		<tr class="publication">
			<td><img src="./projects/2025_motiondreamer.gif" width="100"></td>
			<td>
				<div class="publicationsTitle"><a href="https://lukas.uzolas.com/MotionDreamer/">MotionDreamer: Zero-Shot 3D Mesh Animation from Video Diffusion Models</a></div>
				<div class="publicationsAuthors">Lukas Uzolas, Elmar Eisemann, <b>Petr Kellnhofer</b></div>
				<div class="publicationsCitation">3DV 2025</div>
				<table>
					<tbody><tr>
					<td class="pdfIcon"></td>
					<td class="publicationLinkText"><a href="https://arxiv.org/abs/2405.20155">PDF</a></td>
					<td class="projectPageIcon"></td>
					<td class="publicationLinkText"><a href="https://lukas.uzolas.com/MotionDreamer/">Project Page</a>
					</td></tr>
				</tbody></table>				
			</td>
		</tr>

		<tr class="year"><td colspan="2">2024</td></tr>		
		<tr class="publication">
			<td><img src="./projects/2024_sheared-filtering.gif" width="100"></td>
			<td>
				<div class="publicationsTitle"><a href="https://graphics.tudelft.nl/Publications-new/2024/LGKE24/">Sheared Polygonal Texture Filtering</a></div>
				<div class="publicationsAuthors">Guowei Lu, Jerry Guo, <b>Petr Kellnhofer</b>, Elmar Eisemann</div>
				<div class="publicationsCitation">Graphics Interface 2024 <a href="https://graphicsinterface.org/awards/michael-a-j-sweeney-award/" class="important">[Michael A. J. Sweeney Award (Best Student Paper)]</a></div>
				<table>
					<tbody><tr>
					<td class="pdfIcon"></td>
					<td class="publicationLinkText"><a href="https://graphics.tudelft.nl/Publications-new/2024/LGKE24/paper.pdf">PDF</a></td>
					<td class="projectPageIcon"></td>
					<td class="publicationLinkText"><a href="https://graphics.tudelft.nl/Publications-new/2024/LGKE24/">Project Page</a>
					</td></tr>
				</tbody></table>				
			</td>
		</tr>
		
		<tr class="year"><td colspan="2">2023</td></tr>		
		<tr class="publication">
			<td><img src="./projects/2023_dynamic-points.gif" width="100"></td>
			<td>
				<div class="publicationsTitle"><a href="https://lukas.uzolas.com/Articulated-Point-NeRF/">Template-free Articulated Neural Point Clouds for Reposable View Synthesis</a></div>
				<div class="publicationsAuthors">Lukas Uzolas, Elmar Eisemann, <b>Petr Kellnhofer</b></div>
				<div class="publicationsCitation">NeurIPS 2023</div>
				<table>
					<tbody><tr>
					<td class="pdfIcon"></td>
					<td class="publicationLinkText"><a href="https://arxiv.org/abs/2305.19065">PDF</a></td>
					<td class="projectPageIcon"></td>
					<td class="publicationLinkText"><a href="https://lukas.uzolas.com/Articulated-Point-NeRF/"">Project Page</a>
					</td></tr>
				</tbody></table>				
			</td>
		</tr>
		<tr class="publication">
			<td><img src="./projects/cog_csf_before-after_3_2.gif" width="100"></td>
			<td>
				<div class="publicationsTitle"><a href="https://www.computationalimaging.org/publications/attention-aware/">Towards Attention-aware Foveated Rendering</a></div>
				<div class="publicationsAuthors">Brooke Krajancich, <b>Petr Kellnhofer</b>, Gordon Wetzstein</div>
				<div class="publicationsCitation">SIGGRAPH 2023 (ACM Transactions on Graphics journal) <a href="https://blog.siggraph.org/2023/07/siggraph-2023-technical-papers-awards-best-papers-honorable-mentions-and-test-of-time.html/" class="important">[Honorable mention]</a></div>
				<table>
					<tbody><tr>
					<td class="pdfIcon"></td>
					<td class="publicationLinkText"><a href="https://arxiv.org/abs/2302.01368">PDF</a></td>
					<td class="projectPageIcon"></td>
					<td class="publicationLinkText"><a href="https://www.computationalimaging.org/publications/attention-aware/">Project Page</a>
					</td></tr>
				</tbody></table>				
			</td>
		</tr>

		<tr class="year"><td colspan="2">2022</td></tr>
		<tr class="publication">
			<td><img src="./projects/gnarf_2022.gif"></td>
			<td>
				<div class="publicationsTitle"><a href="https://www.computationalimaging.org/publications/gnarf/">Generative Neural Articulated Radiance Fields</a></div>
				<div class="publicationsAuthors">Alexander W. Bergman*, <b>Petr Kellnhofer*</b>, Wang Yifan*, Eric R. Chan*, David B. Lindell, Gordon Wetzstein</div>
				<div class="publicationsCitation">NeurIPS 2022</div>
				<table>
					<tbody><tr>
					<td class="pdfIcon"></td>
					<td class="publicationLinkText"><a href="https://arxiv.org/abs/2206.14314">PDF</a></td>
					<td class="projectPageIcon"></td>
					<td class="publicationLinkText"><a href="https://www.computationalimaging.org/publications/gnarf/">Project Page</a>
					</td></tr>
				</tbody></table>				
			</td>
		</tr>
		
		<tr class="year"><td colspan="2">2021</td></tr>
		<tr class="publication">
			<td><img src="./projects/meta_nlr_2021.png"></td>
			<td>
				<div class="publicationsTitle"><a href="https://www.computationalimaging.org/publications/metanlr/">Fast Training of Neural Lumigraph Representations using Meta Learning</a></div>
				<div class="publicationsAuthors">Alexander W. Bergman, <b>Petr Kellnhofer</b>, Gordon Wetzstein</div>
				<div class="publicationsCitation">NeurIPS 2021</div>
				<table>
					<tbody><tr>
					<td class="pdfIcon"></td>
					<td class="publicationLinkText"><a href="https://arxiv.org/abs/2106.14942">PDF</a></td>
					<td class="projectPageIcon"></td>
					<td class="publicationLinkText"><a href="https://www.computationalimaging.org/publications/metanlr/">Project Page</a>
					</td></tr>
				</tbody></table>				
			</td>
		</tr>
		<tr class="publication">
			<td><img src="./projects/cff_sg2021.gif"></td>
			<td>
				<div class="publicationsTitle"><a href="http://www.computationalimaging.org/publications/cff/">A Perceptual Model for Eccentricity-dependent Spatio-temporal Flicker Fusion and its Applications to Foveated Graphics</a></div>
				<div class="publicationsAuthors">Brooke Krajancich, <b>Petr Kellnhofer</b>, Gordon Wetzstein</div>
				<div class="publicationsCitation">ACM SIGGRAPH 2021</div>
				<table>
					<tbody><tr>
					<td class="pdfIcon"></td>
					<td class="publicationLinkText"><a href="https://arxiv.org/abs/2104.13514">PDF</a></td>
					<td class="projectPageIcon"></td>
					<td class="publicationLinkText"><a href="http://www.computationalimaging.org/publications/cff/">Project Page</a>
					</td></tr>
				</tbody></table>				
			</td>
		</tr>
		<tr class="publication">
			<td><img src="./projects/nlr_cvpr2021.gif"></td>
			<td>
				<div class="publicationsTitle"><a href="http://www.computationalimaging.org/publications/nlr/">Neural Lumigraph Rendering</a></div>
				<div class="publicationsAuthors"><b>Petr Kellnhofer</b>, Lars Jebe, Andrew Jones, Kari Pulli, Gordon Wetzstein</div>
				<div class="publicationsCitation">IEEE CVPR 2021 <span class="important">(Oral)</span> <span style="color: red">[Best paper candidate]</span></div>
				<table>
					<tbody><tr>
					<td class="pdfIcon"></td>
					<td class="publicationLinkText"><a href="https://arxiv.org/abs/2103.11571">PDF</a></td>
					<td class="projectPageIcon"></td>
					<td class="publicationLinkText"><a href="http://www.computationalimaging.org/publications/nlr/">Project Page</a>
					</td></tr>
				</tbody></table>				
			</td>
		</tr>
		<tr class="publication">
			<td><img src="./projects/pigan.gif"></td>
			<td>
				<div class="publicationsTitle"><a href="https://marcoamonteiro.github.io/pi-GAN-website/">pi-GAN: Periodic Implicit Generative Adversarial Networks for 3D-Aware Image Synthesis</a></div>
				<div class="publicationsAuthors">Eric Chan*, Marco Monteiro*, <b>Petr Kellnhofer</b>, Jiajun Wu, Gordon Wetzstein</div>
				<div class="publicationsCitation">IEEE CVPR 2021 <span class="important">(Oral)</span></div>
				<table>
					<tbody><tr>
					<td class="pdfIcon"></td>
					<td class="publicationLinkText"><a href="https://arxiv.org/pdf/2012.00926.pdf">PDF</a></td>
					<td class="projectPageIcon"></td>
					<td class="publicationLinkText"><a href="https://marcoamonteiro.github.io/pi-GAN-website/">Project Page</a>
					</td></tr>
				</tbody></table>				
			</td>
		</tr>
		<tr class="publication">
			<td><img src="./projects/holo2021.png"></td>
			<td>
				<div class="publicationsTitle"><a href="http://cgh.csail.mit.edu/">Tensor Holography: Towards Real-time Photorealistic 3D Holography with Deep Neural Networks</a></div>
				<div class="publicationsAuthors">Liang Shi, Beichen Li, Changil Kim, <b>Petr Kellnhofer</b>, Wojciech Matusik</div>
				<div class="publicationsCitation"><span class="important">Nature</span>, 592 (234–239), 2021</div>
				<table>
					<tbody><tr>
					<td class="pdfIcon"></td>
					<td class="publicationLinkText"><a href="https://www.nature.com/articles/s41586-020-03152-0">PDF</a></td>
					<td class="projectPageIcon"></td>
					<td class="publicationLinkText"><a href="http://cgh.csail.mit.edu/">Project Page</a>
					</td></tr>
				</tbody></table>				
			</td>
		</tr>
		
		<tr class="year"><td colspan="2">2020</td></tr>
		<tr class="publication">
			<td><img src="./projects/gcstereo2020.png"></td>
			<td>
				<div class="publicationsTitle"><a href="http://www.computationalimaging.org/publications/gcstereo/">Optimizing Depth Perception in Virtual and Augmented Reality through Gaze-contingent Stereo Rendering</a></div>
				<div class="publicationsAuthors">Brooke Krajancich, <b>Petr Kellnhofer</b>, Gordon Wetzstein</div>
				<div class="publicationsCitation">ACM Transactions on Graphics 39(6) (Proc. SIGGRAPH Asia 2020, Daegu, South Korea).</div>
				<table>
					<tbody><tr>
					<td class="pdfIcon"></td>
					<td class="publicationLinkText"><a href="http://www.computationalimaging.org/wp-content/uploads/2020/08/GCstereo_SIGAsia2020_paper.pdf">PDF</a></td>
					<td class="projectPageIcon"></td>
					<td class="publicationLinkText"><a href="http://www.computationalimaging.org/publications/gcstereo/">Project Page</a>
					</td></tr>
				</tbody></table>				
			</td>
		</tr>
		
		<tr class="year"><td colspan="2">2019</td></tr>
		<tr class="publication">
			<td><img src="./projects/gaze360.jpg"></td>
			<td>
				<div class="publicationsTitle"><a href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Kellnhofer_Gaze360_Physically_Unconstrained_Gaze_Estimation_in_the_Wild_ICCV_2019_paper.pdf">Gaze360: Physically Unconstrained Gaze Estimation in the Wild</a></div>
				<div class="publicationsAuthors"><b>Petr Kellnhofer*</b>, Adrià Recasens*, Simon Stent, Wojciech Matusik, and Antonio Torralba</div>
				<div class="publicationsCitation">ICCV 2019 (Soul, South Korea, October 29th - November 1st 2019). <span class="note">* Denotes equal contribution.</span></div>
				<table>
					<tbody><tr>
					<td class="pdfIcon"></td>
					<td class="publicationLinkText"><a href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Kellnhofer_Gaze360_Physically_Unconstrained_Gaze_Estimation_in_the_Wild_ICCV_2019_paper.pdf">PDF</a></td>
					</td></tr>
				</tbody></table>				
			</td>
		</tr>
		<tr class="publication">
			<td><img src="./projects/stag_nature2019.png"></td>
			<td>
				<div class="publicationsTitle"><a href="http://humangrasp.io/">Learning the signatures of the human grasp
using a scalable tactile glove</a></div>
				<div class="publicationsAuthors">Subramanian Sundaram, <b>Petr Kellnhofer</b>, Yunzhu Li, Jun-Yan Zhu, Antonio Torralba, and Wojciech Matusik</div>
				<div class="publicationsCitation"><span class="important">Nature</span>, 569 (7758), 2019</div>
				<table>
					<tbody><tr>
					<td class="pdfIcon"></td>
					<td class="publicationLinkText"><a href="https://www.nature.com/articles/s41586-019-1234-z">PDF</a></td>
					<td class="projectPageIcon"></td>
					<td class="publicationLinkText"><a href="http://humangrasp.io/">Project Page</a>
					</td></tr>
				</tbody></table>				
			</td>
		</tr>
		<tr class="publication">
			<td><img src="./projects/knitting_icml2019.png"></td>
			<td>
				<div class="publicationsTitle"><a href="http://deepknitting.csail.mit.edu/">Neural Inverse Knitting: From Images to Manufacturing Instructions</a></div>
				<div class="publicationsAuthors">Alexandre Kaspar*, Tae-Hyun Oh*, Liane Makatura, <b>Petr Kellnhofer</b>, Jacqueline Aslarus, and Wojciech Matusik</div>
				<div class="publicationsCitation">ICML 2019 (Long Beach, CA, USA, 10th - 15th June 2019). <span class="note">* Denotes equal contribution.</span></div>
				<table>
					<tbody><tr>
					<td class="pdfIcon"></td>
					<td class="publicationLinkText"><a href="https://arxiv.org/abs/1902.02752">PDF</a></td>
					<td class="projectPageIcon"></td>
					<td class="publicationLinkText"><a href="http://deepknitting.csail.mit.edu/">Project Page</a>
					</td></tr>
				</tbody></table>				
			</td>
		</tr>
		
		<tr class="year"><td colspan="2">2018</td></tr>
		<tr class="publication">
			<td><img src="./projects/zoomnet.png"></td>
			<td>
				<div class="publicationsTitle"><a href="https://github.com/recasens/Saliency-Sampler">Learning to Zoom: a Saliency-Based Sampling Layer for Neural Networks</a></div>
				<div class="publicationsAuthors">Adrià Recasens*, <b>Petr Kellnhofer*</b>, Simon Stent, Wojciech Matusik, and Antonio Torralba</div>
				<div class="publicationsCitation">ECCV 2018 (Munich, Germany, 8th - 14th September 2018). <span class="note">* Denotes equal contribution.</span></div>
				<table>
					<tbody><tr>
					<td class="pdfIcon"></td>
					<td class="publicationLinkText"><a href="https://arxiv.org/abs/1809.03355">PDF</a></td>
					<td class="projectPageIcon"></td>
					<td class="publicationLinkText"><a href="https://github.com/recasens/Saliency-Sampler">Project Page</a>
					</td></tr>
				</tbody></table>				
			</td>
		</tr>
		<tr class="publication">
			<td><img src="./projects/flash_noflash.png"></td>
			<td>
				<div class="publicationsTitle"><a href="http://yaksoy.github.io/flashambient/">A Dataset of Flash and Ambient Illumination Pairs from the Crowd</a></div>
				<div class="publicationsAuthors">Yagiz Aksoy, Changil Kim, <b>Petr Kellnhofer</b>, Sylvain Paris, Mohamed Elgharib, Marc Pollefeys, and Wojciech Matusik</div>
				<div class="publicationsCitation">ECCV 2018 (Munich, Germany, 8th - 14th September 2018).</div>
				<table>
					<tbody><tr>
					<td class="pdfIcon"></td>
					<td class="publicationLinkText"><a href="http://yaksoy.github.io/papers/ECCV18-flashambient.pdf">PDF</a></td>
					<td class="projectPageIcon"></td>
					<td class="publicationLinkText"><a href="http://yaksoy.github.io/flashambient/">Project Page</a>
					</td></tr>
				</tbody></table>				
			</td>
		</tr>
		
		<tr class="year"><td colspan="2">2017</td></tr>
		<tr class="publication">
			<td><img src="./projects/home3d_sg2017.png"></td>
			<td>
				<div class="publicationsTitle"><a href="https://people.csail.mit.edu/pkellnho/Home3D">3DTV at Home: Eulerian-Lagrangian Stereo-to-Multiview Conversion</a></div>
				<div class="publicationsAuthors"><b>Petr Kellnhofer</b>, Piotr Didyk, Szu-Po Wang, Pitchaya Sitthi-Amorn, William Freeman, Fredo Durand, and Wojciech Matusik</div>
				<div class="publicationsCitation">ACM Transactions on Graphics 36(4) (Proc. SIGGRAPH 2017, Los Angeles, California, USA, 30th - 3rd August 2017).</div>
				<table>
					<tbody><tr>
					<td class="pdfIcon"></td>
					<td class="publicationLinkText"><a href="http://dl.acm.org/citation.cfm?doid=3072959.3073617">PDF</a></td>
					<td class="projectPageIcon"></td>
					<td class="publicationLinkText"><a href="https://people.csail.mit.edu/pkellnho/Home3D">Project Page</a>
					</td></tr>
				</tbody></table>				
			</td>
		</tr>
		<tr class="publication">
			<td><img src="./projects/varifocal_sg2017et.png"></td>
			<td>
				<div class="publicationsTitle"><span href="https://people.csail.mit.edu/pkellnho/Home3D">Membrane AR: Varifocal, Wide-Field-of-the-View Augmented Reality Display from Deformable Membranes</span></div>
				<div class="publicationsAuthors">D. Dunn, C. Tippets, K. Torell, <b>P. Kellnhofer</b>, K. Akşit, P. Didyk, K. Myszkowski, D. Luebke, and H. Fuch</div>
				<div class="publicationsCitation">ACM SIGGRAPH Emerging Technologies (Los Angeles, California, USA, 30th - 3rd August 2017).</div>
				<table>
					<tbody><tr>
					<td class="pdfIcon"></td>
					<td class="publicationLinkText"><a href="https://people.mpi-inf.mpg.de/alumni/d4/2018/pkellnho/download/membraneAR-Demo.pdf">PDF</a></td>
					<td class="projectPageIcon"></td>
					<td class="publicationLinkText"><a href="http://telepresence.web.unc.edu/research/dynamic-focus-augmented-reality-display/">Project Page</a>
					</td></tr>
				</tbody></table>				
			</td>
		</tr>
		<tr class="publication">
			<td><img src="./projects/2d_to_3d_tvcg2017.png"></td>
			<td>
				<div class="publicationsTitle"><a href="http://resources.mpi-inf.mpg.de/StereoCueFusion/">Perceptual real-time 2D-to-3D conversion using cue fusion [extended version]</a></div>
				<div class="publicationsAuthors">Thomas Leimkühler, <b>Petr Kellnhofer</b>, Tobias Ritschel, Karol Myszkowski, Hans-Peter Seidel</div>
				<div class="publicationsCitation">IEEE Transactions on Visualization and Computer Graphics, 2017.</div>
				<table>
					<tbody><tr>
					<td class="pdfIcon"></td>
					<td class="publicationLinkText"><a href="http://resources.mpi-inf.mpg.de/StereoCueFusion/StereoCueFusionPaper_TVCG.pdf">PDF</a></td>
					<td class="projectPageIcon"></td>
					<td class="publicationLinkText"><a href="http://resources.mpi-inf.mpg.de/StereoCueFusion/">Project Page</a>
					</td></tr>
				</tbody></table>				
			</td>
		</tr>
		<tr class="publication">
			<td><img src="./projects/varifocal_vr2017.png"></td>
			<td>
				<div class="publicationsTitle"><a href="http://telepresence.web.unc.edu/research/dynamic-focus-augmented-reality-display/">Wide Field Of View Varifocal Near-Eye Display Using See-Through Deformable Membrane Mirrors</a> <span class="award">[Best Paper Award]</span></div>
				<div class="publicationsAuthors">D. Dunn, C. Tippets, K. Torell, <b>P. Kellnhofer</b>, K. Akşit, P. Didyk, K. Myszkowski, D. Luebke, and H. Fuch</div>
				<div class="publicationsCitation">IEEE Transactions on Visualization and Computer Graphics (Selected Proceedings, IEEE Virtual Reality 2017, Los Angeles, CA).</div>
				<table>
					<tbody><tr>
					<td class="pdfIcon"></td>
					<td class="publicationLinkText"><a href="http://telepresence.web.unc.edu/files/2017/01/Dunn_2017_TVCG_MembraneAR.pdf">PDF</a></td>
					<td class="projectPageIcon"></td>
					<td class="publicationLinkText"><a href="http://telepresence.web.unc.edu/research/dynamic-focus-augmented-reality-display/">Project Page</a>
					</td></tr>
				</tbody></table>				
			</td>
		</tr>
		<tr class="year"><td colspan="2">2016</td></tr>
		<tr class="publication">
			<td><img src="./projects/phd.png"></td>
			<td>
				<div class="publicationsTitle"><a href="https://people.mpi-inf.mpg.de/alumni/d4/2018/pkellnho/phd.pdf">Perceptual modeling for stereoscopic 3D</a></div>
				<div class="publicationsAuthors"><b>Petr Kellnhofer</b></div>
				<div class="publicationsCitation">PhD thesis - Universität des Saarlandes, defended on 4th November 2016.</div>
				<table>
					<tbody><tr>
					<td class="pdfIcon"></td>
					<td class="publicationLinkText"><a href="https://people.mpi-inf.mpg.de/alumni/d4/2018/pkellnho/phd.pdf">PDF</a></td>
					</td></tr>
				</tbody></table>				
			</td>
		</tr>
		<tr class="publication">
			<td><img src="./projects/parallax_stereo_sga2016.png"></td>
			<td>
				<div class="publicationsTitle"><a href="http://resources.mpi-inf.mpg.de/StereoParallax/">Motion Parallax in Stereo 3D: Model and Applications</a></div>
				<div class="publicationsAuthors"><b>Petr Kellnhofer</b>, Piotr Didyk, Tobias Ritschel, Belen Masia, Karol Myszkowski, Hans-Peter Seidel</div>
				<div class="publicationsCitation">ACM Transactions on Graphics 35(6) (Proc. SIGGRAPH Asia 2016, The Venetian Macao, Macao, 5th - 8th December 2016).</div>
				<table>
					<tbody><tr>
					<td class="pdfIcon"></td>
					<td class="publicationLinkText"><a href="http://resources.mpi-inf.mpg.de/StereoParallax/StereoParallax.pdf">PDF</a></td>
					<td class="projectPageIcon"></td>
					<td class="publicationLinkText"><a href="http://resources.mpi-inf.mpg.de/StereoParallax/">Project Page</a>
					</td></tr>
				</tbody></table>				
			</td>
		</tr>
		<tr class="publication">
			<td><img src="./projects/transformationawaremetric_jei2016.png"></td>
			<td>
				<div class="publicationsTitle"><a href="http://resources.mpi-inf.mpg.de/TransformationAwareMetric/#jei">A Transformation-Aware Perceptual Image Metric</a></div>
				<div class="publicationsAuthors"><b>Petr Kellnhofer</b>, Tobias Ritschel, Karol Myszkowski, Hans-Peter Seidel</div>
				<div class="publicationsCitation">Journal of Electronic Imaging, 2016.</div>
				<table>
					<tbody><tr>
					<td class="pdfIcon"></td>
					<td class="publicationLinkText"><a href="http://resources.mpi-inf.mpg.de/TransformationAwareMetric/kellnhofer_jei2016.pdf">PDF</a></td>
					<td class="projectPageIcon"></td>
					<td class="publicationLinkText"><a href="http://resources.mpi-inf.mpg.de/TransformationAwareMetric/">Project Page</a>
					</td></tr>
				</tbody></table>				
			</td>
		</tr>
		<tr class="publication">
			<td><img src="./projects/gaze3d_sg2016.png"></td>
			<td>
				<div class="publicationsTitle"><a href="http://resources.mpi-inf.mpg.de/GazeStereo3D/">GazeStereo3D: Seamless Disparity Manipulations</a></div>
				<div class="publicationsAuthors"><b>Petr Kellnhofer</b>, Piotr Didyk, Karol Myszkowski, Mohamed M. Hefeeda, Hans-Peter Seidel, Wojciech Matusik</div>
				<div class="publicationsCitation">ACM Transactions on Graphics 35(4) (Proc. SIGGRAPH 2016, Anaheim, California, USA, 24th - 28th July 2016).</div>
				<table>
					<tbody><tr>
					<td class="pdfIcon"></td>
					<td class="publicationLinkText"><a href="http://resources.mpi-inf.mpg.de/GazeStereo3D/GazeStereo3D.pdf">PDF</a></td>
					<td class="projectPageIcon"></td>
					<td class="publicationLinkText"><a href="http://resources.mpi-inf.mpg.de/GazeStereo3D/">Project Page</a>
					</td></tr>
				</tbody></table>				
			</td>
		</tr>
		<tr class="publication">
			<td><img src="./projects/cvpr2016.png"></td>
			<td>
				<div class="publicationsTitle"><a href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Krafka_Eye_Tracking_for_CVPR_2016_paper.pdf">Eye Tracking for Everyone</a></div>
				<div class="publicationsAuthors">Aditya Khosla*, Kyle Krafka*, <b>Petr Kellnhofer</b>, Harini Kannan, Suchi Bhandarkar, Wojciech Matusik, Antonio Torralba</div>
				<div class="publicationsCitation">IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Las Vegas, USA, 26th June - 1st July 2016.</div>
				<table>
					<tbody><tr>
					<td class="pdfIcon"></td>
					<td class="publicationLinkText"><a href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Krafka_Eye_Tracking_for_CVPR_2016_paper.pdf">PDF</a></td>
					</td></tr>
				</tbody></table>				
			</td>
		</tr>
		<tr class="publication">
			<td><img src="./projects/gi2016.png"></td>
			<td>
				<div class="publicationsTitle"><a href="http://resources.mpi-inf.mpg.de/StereoCueFusion/">Perceptual real-time 2D-to-3D conversion using cue fusion</a> <span class="award">[Best Student Paper Award]</span></div>
				<div class="publicationsAuthors">Thomas Leimkühler, <b>Petr Kellnhofer</b>, Tobias Ritschel, Karol Myszkowski, Hans-Peter Seidel</div>
				<div class="publicationsCitation">Graphics Interface 2016, Victoria, British Columbia, Canada, 31st May - 3rd June 2016.</div>
				<table>
					<tbody><tr>
					<td class="pdfIcon"></td>
					<td class="publicationLinkText"><a href="http://resources.mpi-inf.mpg.de/StereoCueFusion/StereoCueFusionPaper.pdf">PDF</a></td>
					<td class="projectPageIcon"></td>
					<td class="publicationLinkText"><a href="http://resources.mpi-inf.mpg.de/StereoCueFusion/">Project Page</a>
					</td></tr>
				</tbody></table>				
			</td>
		</tr>
		<tr class="year"><td>2015</td></tr>
		<tr class="publication">
			<td><img src="./projects/sap2015.png"></td>
			<td>
				<div class="publicationsTitle"><a href="http://resources.mpi-inf.mpg.de/StereoCueFusion/WhatMakes3D">What makes 2D-to-3D stereo conversion perceptually plausible?</a> <span class="award">[Best Presentation Award]</span> <span style="font-weight: normal">(presented by T. Leimkühler)</span></div>
				<div class="publicationsAuthors"><b>Petr Kellnhofer</b>, Thomas Leimkühler, Tobias Ritschel, Karol Myszkowski, Hans-Peter Seidel</div>
				<div class="publicationsCitation">ACM Symposium on Applied Perception (Tübingen/Germany, 13-14 September 2015), 2015.</div>
				<table>
					<tbody><tr>
					<td class="pdfIcon"></td>
					<td class="publicationLinkText"><a href="http://resources.mpi-inf.mpg.de/StereoCueFusion/WhatMakes3D/article.pdf">PDF</a></td>
					<td class="projectPageIcon"></td>
					<td class="publicationLinkText"><a href="http://resources.mpi-inf.mpg.de/StereoCueFusion/WhatMakes3D">Project Page</a>
					</td></tr>
				</tbody></table>				
			</td>
		</tr>
		<tr class="publication">
			<td><img src="./projects/darknoise_egsr2015.png"></td>
			<td>
				<div class="publicationsTitle"><a href="http://resources.mpi-inf.mpg.de/DarkNoise/">Modeling Luminance Perception at Absolute Threshold</a></div>
				<div class="publicationsAuthors"><b>Petr Kellnhofer</b>, Tobias Ritschel, Karol Myszkowski, Elmar Eisemann, Hans-Peter Seidel</div>
				<div class="publicationsCitation">Computer Graphics Forum  (Proc. EGSR 2015, Darmstadt/Germany, 24-26 June 2015), 2015.</div>
				<table>
					<tbody><tr>
					<td class="pdfIcon"></td>
					<td class="publicationLinkText"><a href="http://resources.mpi-inf.mpg.de/DarkNoise/article.pdf">PDF</a></td>
					<td class="projectPageIcon"></td>
					<td class="publicationLinkText"><a href="http://resources.mpi-inf.mpg.de/DarkNoise/">Project Page</a>
					</td></tr>
				</tbody></table>				
			</td>
		</tr>
		<tr class="publication">
			<td><img src="./projects/transformationawaremetric_spie2015.png"></td>
			<td>
				<div class="publicationsTitle"><a href="http://resources.mpi-inf.mpg.de/TransformationAwareMetric/">A Transformation-Aware Perceptual Image Metric</a> <span class="award">[Best Student Paper Award]</span></div>
				<div class="publicationsAuthors"><b>Petr Kellnhofer</b>, Tobias Ritschel, Karol Myszkowski, Hans-Peter Seidel</div>
				<div class="publicationsCitation">IS&amp;T/SPIE Electronic Imaging 2015 (Human Vision and Electronic Imaging XX, San Francisco/CA/USA, 8-12 February 2015), 2015.</div>
				<table>
					<tbody><tr>
					<td class="pdfIcon"></td>
					<td class="publicationLinkText"><a href="http://resources.mpi-inf.mpg.de/TransformationAwareMetric/spie2015.pdf">PDF</a></td>
					<td class="projectPageIcon"></td>
					<td class="publicationLinkText"><a href="http://resources.mpi-inf.mpg.de/TransformationAwareMetric/">Project Page</a>
					</td></tr>
				</tbody></table>				
			</td>
		</tr>
		<tr class="year"><td>2014</td></tr>
		<tr class="publication">
			<td><img src="./projects/darkstereo_sap2014.png"></td>
			<td>
				<div class="publicationsTitle"><a href="http://resources.mpi-inf.mpg.de/DarkStereo/">Stereo Day-for-Night: Retargeting Disparity for Scotopic Vision</a></div>
				<div class="publicationsAuthors"><b>Petr Kellnhofer</b>, Tobias Ritschel, Peter Vangorp, Karol Myszkowski, Hans-Peter Seidel</div>
				<div class="publicationsCitation">ACM Transactions on Applied Perception (TAP) - Special issue SAP 2014 (Symposium on Applied Perception 2014, Vancouver, 8-9 August 2014), 2014.</div>
				<table>
					<tbody><tr>
					<td class="pdfIcon"></td>
					<td class="publicationLinkText"><a href="http://resources.mpi-inf.mpg.de/DarkStereo/kellnhofer-sap2014.pdf">PDF</a></td>
					<td class="projectPageIcon"></td>
					<td class="publicationLinkText"><a href="http://resources.mpi-inf.mpg.de/DarkStereo/">Project Page</a>
					</td></tr>
				</tbody></table>				
			</td>
		</tr>
		<tr class="publication">
			<td><img src="./projects/stereorefraction_eg2014b.png"></td>
			<td>
				<div class="publicationsTitle"><a href="http://resources.mpi-inf.mpg.de/StereoRefraction/">Manipulating Refractive and Reflective Binocular Disparity</a></div>
				<div class="publicationsAuthors">&#321;ukasz D&#261;ba&#322;a, <b>Petr Kellnhofer</b>, Tobias Ritschel, Piotr Didyk, Krzysztof Templin, Karol Myszkowski, Przemys&#322;aw Rokita, Hans-Peter Seidel</div>
				<div class="publicationsCitation">Computer Graphics Forum 33(2) (Proc. Eurographics 2014, Strasbourg/France, 7-11 April 2014), 2014.</div>
				<table>
					<tbody><tr>
					<td class="pdfIcon"></td>
					<td class="publicationLinkText"><a href="http://resources.mpi-inf.mpg.de/StereoRefraction/eg2014.pdf">PDF</a></td>
					<td class="projectPageIcon"></td>
					<td class="publicationLinkText"><a href="http://resources.mpi-inf.mpg.de/StereoRefraction/">Project Page</a>
					</td></tr>
				</tbody></table>				
			</td>
		</tr>
		<tr class="publication">
			<td><img src="./projects/spie2014.png"></td>
			<td>
				<div class="publicationsTitle"><a href="http://resources.mpi-inf.mpg.de/TemporalStereo#spie2014">Improving Perception of Binocular Stereo Motion on 3D Display Devices</a></div>
				<div class="publicationsAuthors"><b>Petr Kellnhofer</b>, Tobias Ritschel, Karol Myszkowski, Hans-Peter Seidel</div>
				<div class="publicationsCitation">IS&amp;T/SPIE Electronic Imaging 2014 (Stereoscopic Displays and Applications XXV, San Francisco/CA/USA, 3-6 February 2014), 2014.</div>
				<table>
					<tbody><tr>
					<td class="pdfIcon"></td>
					<td class="publicationLinkText"><a href="http://resources.mpi-inf.mpg.de/TemporalStereo/spie2014.pdf">PDF</a></td>
					<td class="projectPageIcon"></td>
					<td class="publicationLinkText"><a href="http://resources.mpi-inf.mpg.de/TemporalStereo#spie2014">Project Page</a>
					</td></tr>
				</tbody></table>				
			</td>
		</tr>
		<tr class="year"><td>2013</td></tr>
		<tr class="publication">
			<td><img src="./projects/temporal_stereo.png"></td>
			<td>
				<div class="publicationsTitle"><a href="http://resources.mpi-inf.mpg.de/TemporalStereo#egsr2013">Optimizing Disparity for Motion in Depth</a></div>
				<div class="publicationsAuthors"><b>Petr Kellnhofer</b>, Tobias Ritschel, Karol Myszkowski, Hans-Peter Seidel</div>
				<div class="publicationsCitation">Computer Graphics Forum  (Proc. EGSR 2013, Zaragoza/Spain, 19-21 June 2013), 2013.</div>
				<table>
					<tbody><tr>
					<td class="pdfIcon"></td>
					<td class="publicationLinkText"><a href="http://resources.mpi-inf.mpg.de/TemporalStereo/articleFull.pdf">PDF</a></td>
					<td class="projectPageIcon"></td>
					<td class="publicationLinkText"><a href="http://resources.mpi-inf.mpg.de/TemporalStereo#egsr2013">Project Page</a>
					</td></tr>
				</tbody></table>				
			</td>
		</tr>
		<tr class="year"><td>2012</td></tr>
		<tr class="publication">
			<td><img src="./projects/time_convenient.png"></td>
			<td>
				<div class="publicationsTitle">Time-Convenient Deformation of Musculoskeletal System</div>
				<div class="publicationsAuthors"><b>Petr Kellnhofer</b>, Josef Kohout</div>
				<div class="publicationsCitation">In Proceedings of the Algoritmy 2012 Conference (Podbanske/Slovakia, 9-14 September 2012), 2012.</div>
				<table>
					<tbody><tr>
					<td class="pdfIcon"></td>
					<td class="publicationLinkText"><a href="http://www.iam.fmph.uniba.sk/algoritmy2012/zbornik/25Kellnhoferf.pdf">PDF</a></td>
					</tr>
				</tbody></table>		
			</td>
		</tr>
		<tr class="publication">
			<td><img src="./projects/fast_deform.png"></td>
			<td>
				<div class="publicationsTitle">Fast Deformation for Modelling of Musculoskeletal System</div>
				<div class="publicationsAuthors">Josef Kohout, <b>Petr Kellnhofer</b>, Saulo Martelli</div>
				<div class="publicationsCitation">In Proceedings of the International Conference on Computer Graphics Theory and Applications: GRAPP 2012 (Rome/Italy, 24-26 February 2012), 2012.</div>
				<table>
					<tbody><tr>
					<td class="pdfIcon"></td>
					<td class="publicationLinkText"><a href="https://otik.uk.zcu.cz/bitstream/handle/11025/478/maintext-1.pdf?sequence=1">PDF</a></td>
					</tr>
				</tbody></table>		
			</td>
		</tr>
		</tbody>
	</table>


	<h1 id="talks" class="clearpara">Invited Talks</h1>
	<!-- put the most recent entries on top of your list -->
	<ul>
		<li>Invited talk at the <a href="https://www.kiv.zcu.cz/en/">CS department of the University of West Bohemia</a>, Czechia, April 2024.</li>
		<li>Invited talk on Gaze Tracking in the Wild at the <a href="https://socialai.nl/team.html">Social AI lab Colloquium</a>, VU University Amsterdam, NL, June 16th, 2022.</li>		
		<li>Invited talk at <a href="https://ieeetv.ieee.org/icra-2020-beyond-soft-robotics-pioneer-perspectives-and-interdisciplinary-collaboration">ICRA 2020 Workshop "Beyond Soft Robotics"</a> (virtual, timestamp 5:34:00).</li>
		<li><a href="https://dyvito.com/news-and-events/">DyViTo Virtual Network Meeting</a> (virtual), University of Zaragoza, Spain, 2020.</li>
		<li>Invited talk at <a href="https://scien.stanford.edu/">The Stanford Center for Image System Engineering (SCIEN)</a>, CA, USA, 2018.</li>
		<li>Tutorial: Perceptual Displays. 3DTV Conference, Budapest, Hungary, 2014.</li>
	</ul>

	<h1 id="awards" class="clearpara">Awards</h1>
	<!-- put the most recent entries on top of your list -->
    <ul>
		<li>
			<a href="https://blog.siggraph.org/2023/07/siggraph-2023-technical-papers-awards-best-papers-honorable-mentions-and-test-of-time.html/">SIGGRAPH 2023 Technical Papers Honorable Mentions Award</a> (Paper: <a href="https://www.computationalimaging.org/publications/attention-aware/">Towards Attention-aware Foveated Rendering</a>)
		</li>
		<li>
			<a href="https://eccv2022.ecva.net/program/outstanding-reviewers/">ECCV 2022 Outstanding Reviewer</a>
		</li>
		<li>
			<a href="https://iclr.cc/Conferences/2022/Reviewers">ICLR 2022 Highlighted Reviewer</a>
		</li>
		<li>
			<a href="https://cvpr2021.thecvf.com/node/290">CVPR 2021 Best Paper Candidate</a> (Paper: <a href="http://www.computationalimaging.org/publications/nlr/">Neural Lumigraph Rendering</a>)
		</li>
		<li>
			<a href="https://www.eg.org/wp/eurographics-awards-programme/phd-award/"><b>Eurographics PhD Award 2018</b></a> - Eurographics Annual Award for Best PhD Thesis (<a href="http://people.mpi-inf.mpg.de/~pkellnho/phd.pdf">Perceptual modeling for stereoscopic 3D</a>)
		</li>
		<li>
			<a href="http://www.uni-saarland.de/page/unigesellschaft/eduard-martin-preis.html">Dr.-Eduard-Martin-Preis 2016/17</a> for the PhD Dissertation (<a href="http://people.mpi-inf.mpg.de/~pkellnho/phd.pdf">Perceptual modeling for stereoscopic 3D</a>)
		</li>
		<li>
			<a href="http://s2017.siggraph.org/content/emerging-technologies">Digital Content Association of Japan Award</a> for the SIGGRAPH 2017  Emerging Technology demo "<a href="http://people.mpi-inf.mpg.de/~pkellnho/download/membraneAR-Demo.pdf">Membrane AR: Varifocal, Wide-Field-of-the-View Augmented Reality Display from Deformable Membranes</a>"
		</li>
		<li>
			Nomination for the <a href="https://www.gi.de/wir-ueber-uns/wettbewerbe/gi-dissertationspreis.html">Gessellschaft für Informatik Best Dissertation Prize</a> 2016 for <a href="http://people.mpi-inf.mpg.de/~pkellnho/phd.pdf">Perceptual modeling for stereoscopic 3D</a>
		</li>
		<li>
			Best Paper Award, IEEE Virtual Reality 2017 (Paper: <a href="http://telepresence.web.unc.edu/research/dynamic-focus-augmented-reality-display/">Wide Field Of View Varifocal Near-Eye Display Using See-Through Deformable Membrane Mirrors</a>)
		</li>
		<li>
			Best Student Paper Award, Graphics Interface 2016 (Paper: <a href="http://resources.mpi-inf.mpg.de/StereoCueFusion/">Perceptual real-time 2D-to-3D conversion using cue fusion</a>)
		</li>
		<li>
			Best Presentation Award, ACM Symp. Applied Perception 2015 (Paper: <a href="http://resources.mpi-inf.mpg.de/StereoCueFusion/WhatMakes3D">What makes 2D-to-3D stereo conversion perceptually plausible?</a>) (presented by <a href="http://people.mpi-inf.mpg.de/~tleimkueh/">T. Leimkühler</a>)
		</li>
		<li>
			Best Student Paper Award, SPIE Conference on Human Vision and Electronic Imaging 2015 (Paper: <a href="http://resources.mpi-inf.mpg.de/TransformationAwareMetric/">A Transformation-Aware Perceptual Image Metric</a>)
		</li>	

		
		<li>
			7th place in <a href="www.acm-spy.cz">Czech ACM Chapter & Slovakia ACM Chapter Student Project of the Year</a> in Master category, 2012, Prague, Czech Republic.
		</li>
		<li>
			1st place in <a href="www.acm-spy.cz">Czech ACM Chapter & Slovakia ACM Chapter Student Project of the Year</a> in Bachelor category, 2010, Prague, Czech Republic.
		</li>
		<li>
			<a href="https://www.cca.cz/">CCA</a> award for the best Bachelor thesis in IT, 2010, Plzeň, Czech Republic.
		</li>
	</ul>
	
	
	
	
	<h1 id="reviewing" class="clearpara">Professional service</h1>
	Committees:
    <ul>
		<li><a href="http://iccvm.org/2025/committee.htm">Computational Visual Media Conference 2025 - Program Committee Member</a></li>
		<li><a href="https://pg2024.hsu.edu.cn/committee.html">Pacific Graphics 2024 - Program Committee Member</a></li>
		<li><a href="https://www.highperformancegraphics.org/2024/organization/">High Performance Graphics (HPG) 2024 - Program Committee Member</a></li>
		<li><a href="https://iccp-conference.org/iccp2024/team/">IEEE International Conference on Computational Photography (ICCP) 2024 - Program Committee Member</a></li>
		<li><a href="https://eg2024.cyens.org.cy/full-papers-ipc/">Eurographics 2024 - Full Papers International Program Committee</a></li>
		<li><a href="https://asia.siggraph.org/2023/about-the-event/siggraph-asia-2023-committee/technical-papers-committee/">SIGGRAPH Asia 2023 - Technical Paper Committee Member Member</a></li>
		<li><a href="https://eg2023.saarland-informatics-campus.de/full-papers-ipc/">Eurographics 2023 - Full Papers & STAR Program Committee Member</a></li>
		<li><a href="https://iccp2023.iccp-conference.org/team/">IEEE International Conference on Computational Photography (ICCP) 2023 - Program Committee Member</a></li>
		<li><a href="https://pg2022.org/#ORGANIZERS">Pacific Graphics 2022 - Program Committee Member</a></li>
		<li><a href="https://sa2022.siggraph.org/en/submissions/technical-papers">SIGGRAPH Asia 2022 - Technical Paper Committee Member Member</a></li>
		<li><a href="https://iccp2022.iccp-conference.org/team/">IEEE International Conference on Computational Photography (ICCP) 2022 - Program Committee Member</a></li>		
		<li><a href="https://sa2019.siggraph.org/submissions/posters/posters-committee">SIGGRAPH Asia 2019 - Technical Briefs and Posters Committee Member</a></li>
	</ul>
	Selected reviewer duties:
	<ul>
		<li>ACM SIGGRAPH, ACM SIGGRAPH Asia, Eurographics, IEEE TVCG, ICCP, IEEE VR, Computers & Graphics, Pacific Graphics, Graphic Interface, ACM Symposium on Applied Perception (SAP), ACM Transactions on Applied Perception (TAP)</li>
		<li>CVPR, ICCV, ECCV, NeurIPS, ICML, ICLR, AAAI, IEEE Winter Conf. on Applications of Computer Vision (WACV), ACM Symposium on Virtual Reality Software and Technology</li>		
	</ul>
	
	<h1 id="media" class="clearpara">Media coverage</h1>
	<!-- put the most recent entries on top of your list -->
    <ul>
		<!-- The glove -->
		<li><a href="http://news.mit.edu/2019/sensor-glove-human-grasp-robotics-0529">MIT News: Sensor-packed glove learns signatures of the human grasp</a></li>
		<li><a href="https://www.nature.com/articles/d41586-019-01593-w">Nature News & Views: Bridging the gap between artificial vision and touch</a></li>
		<li><a href="https://engineeringcommunity.nature.com/posts/49420-learning-dexterity-from-humans">Nature communities: Learning dexterity from humans</a></li>
		<li><a href="https://www.economist.com/science-and-technology/2019/05/30/improving-robots-grasp-requires-a-new-way-to-measure-it-in-humans">The Economist: Improving robots’ grasp requires a new way to measure it in humans</a></li>
		<li><a href="https://www.pbs.org/wgbh/nova/article/electronic-glove-pressure-sensors/">PBS NOVA: This electronic glove gets a grip on human touch</a></li>
		<li><a href="https://www.bbc.co.uk/sounds/play/p079yr9y">BBC Radio</a></li>
		<li><a href="https://www.newscientist.com/article/2204736-smart-glove-works-out-what-youre-holding-from-its-weight-and-shape/">New Scientist: Smart glove works out what you’re holding from its weight and shape</a></li>
		<li><a href="https://www.youtube.com/watch?v=gBpp7KOgG6g">FOX 35 Orlando: Teaching a robot to touch with glove fitted with sensors</a></li>
		<!-- 3D TV -->
		<li><a href="https://www.cnet.com/tech/home-entertainment/you-could-soon-watch-3d-movies-without-ridiculous-glasses/?openLogin=1">CNET: You could soon watch 3D movies without ridiculous glasses</a></li>
		<li><a href="https://mashable.com/2017/07/12/researchers-build-glasses-free-3d-tv-tech/#i11GuY83TPqL">Mashable: 3D TVs were presumed to be dead and gone, but these scientists believe they can bring it back</a></li>
		<li><a href="https://www.engadget.com/2017/07/12/mit-solves-a-major-problem-holding-up-glasses-free-3d-tvs/">Engadget: MIT solves a major problem holding up glasses-free 3D TV</li>
		<li><a href="https://www.dailymail.co.uk/sciencetech/article-4690452/MIT-researchers-reveal-3D-TV-DOESN-T-need-glasses.html">Daily Mail: MIT solves a major problem holding up glasses-free 3D TVs</a></li>
		<li><a href="https://techcrunch.com/2017/07/12/mits-glasses-free-home-3d-tech-could-make-help-3d-movies-more-popular/">TechCrunch: MIT solves a major problem holding up glasses-free 3D TVs</a></li>
		<li><a href="https://www.inverse.com/article/34011-mit-tech-3d-star-wars-glasses-free">Inverse: MIT Tech Will Show 3D 'Star Wars' Without the Silly Glasses</a></li>
		<li><a href="https://www.digitaltrends.com/home-theater/mit-csail-glasses-free-3d-videos/">Digital Trends: Research suggests glasses-free 3D videos could be coming soon to home TVs</a></li>
		<li><a href="https://www.ibtimes.com/study-glasses-free-3d-tvs-may-soon-be-living-rooms-2564746">International Business Times: Study: Glasses-Free 3D TVs May Soon Be In Living Rooms</a></li>
		<li><a href="https://techxplore.com/news/2017-07-d-movies-home-sans-glasses.html">Tech Explore: Watch 3-D movies at home, sans glasses</a></li>
		<li><a href="https://www.techspot.com/news/70104-mit-wants-bring-glasses-free-3d-technology-living.html">TechSpot: MIT wants to bring glasses-free 3D technology to the living room</a></li>
	</ul>


	<h1 id="education" class="clearpara">Education</h1>
	<!-- put the most recent entries on top of your list -->
    <ul>
		<li> 
			September 2012 - December 2016:<br />
			Doctoral student (Dr.-Ing.) at the <a href="http://www.mpi-inf.mpg.de">Max-Planck-Institut f&uuml;r Informatik</a> and the <a href="http://www.uni-saarland.de">Universit&auml;t	des Saarlandes, Saarbr&uuml;cken</a>, <a href="https://en.wikipedia.org/wiki/Saarbr%C3%BCcken">Saarbr&uuml;cken</a>, <a href="https://en.wikipedia.org/wiki/Saarland">Saarland</a>, <a href="https://en.wikipedia.org/wiki/Germany">Germany</a><br /><br />
		</li>
		<li> 
			September 2007 - June 2012:<br />
			Studies in <a href="http://www.kiv.zcu.cz/en/homepage.html">Computer Science</a> on the <a href="http://www.fav.zcu.cz/en/">Faculty of Applied Sciences</a> at the <a href="http://www.zcu.cz/en/">University of West Bohemia</a> in <a href="http://en.wikipedia.org/wiki/Plzen">Plzen</a>, <a href="http://en.wikipedia.org/wiki/Czech_Republic">Czech Republic</a><br />
        Title of Master's Thesis (Diplomarbeit): Non-rigid Transformations for Musculoskeletal Model (supervisor: doc. Ing. Josef Kohout, Ph.D.)<br /><br />
		</li>
    </ul>
	

    <div id="footer"></div>
  </div>
</body>

</html>
